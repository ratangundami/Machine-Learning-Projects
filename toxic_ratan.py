# -*- coding: utf-8 -*-
"""Toxic_ratan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nUpnXyXomhUM3OLY_Usx9bnMqCQ4vx9C
"""

import sys, os, re, csv, codecs, numpy as np, pandas as pd
import matplotlib.pyplot as plt
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation
from keras.layers import Bidirectional, GlobalMaxPool1D
from keras.models import Model
from keras import initializers, regularizers, constraints, optimizers, layers
from google.colab import drive
drive.mount("/content/gdrive")

#Class labels
list_classes = ["toxic", "severe_toxic", "obscene", "threat", "insult", "identity_hate"]

#Read the data
toxicWordsTrain = pd.read_csv("/content/gdrive/My Drive/ML/train.csv");
toxicWordsTest = pd.read_csv("/content/gdrive/My Drive/ML/test.csv")

y_train = toxicWordsTrain[list_classes].values
x_train = toxicWordsTrain["comment_text"]
x_test  = toxicWordsTest["comment_text"]

# Tokenize and Pad
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences

# Create tokenizer
tokenizer = Tokenizer(num_words=None,
                      filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
                      lower=True,
                      split=" ",
                      char_level=False)

# Fit and run tokenizer
tokenizer.fit_on_texts(list(x_train))
tokenized_train = tokenizer.texts_to_sequences(x_train)
tokenized_test = tokenizer.texts_to_sequences(x_test)
word_index = tokenizer.word_index

# Extract variables
vocab_size = len(word_index)
print('Vocab size: {}'.format(vocab_size))
longest = max(len(seq) for seq in tokenized_train)
print("Longest comment size: {}".format(longest))
average = np.mean([len(seq) for seq in tokenized_train])
print("Average comment size: {}".format(average))
stdev = np.std([len(seq) for seq in tokenized_train])
print("Stdev of comment size: {}".format(stdev))
max_len = int(average + stdev * 3)
print('Max comment size: {}'.format(max_len))
print()

# Pad sequences
processed_X_train = pad_sequences(tokenized_train, maxlen=max_len, padding='post', truncating='post')
processed_X_test = pad_sequences(tokenized_test, maxlen=max_len, padding='post', truncating='post')

"""### Embeddings"""

import gensim 
from gensim.models import Word2Vec 

from os import listdir
from numpy import array
from numpy import asarray
from numpy import zeros
from nltk.tokenize import word_tokenize

import nltk
nltk.download('punkt')
l4=[]
for i in x_train:
    t3=word_tokenize(i)
    l4.append(t3)
for i in x_test:
    t3=word_tokenize(i)
    l4.append(t3)
    
#print(l4)
model = Word2Vec(l4, size=300, window=5, min_count=10,sg=1,iter=20)
# summarize vocabulary size in model
model.save("w2v.model")
words = list(model.wv.vocab)
vocab_size = len(words)
vocab_size

model = Word2Vec.load("w2v.model")
model

# save model in ASCII (word2vec) format
filename = 'embedding_word2vec.txt'
model.wv.save_word2vec_format(filename, binary=False)

embedding_dim = 300

# Get embeddings
embeddings_index = {}
f = open('embedding_word2vec.txt')
for line in f:
    values = line.split()
    word = values[0]
    coefs = asarray(values[1:], dtype='float32')
    embeddings_index[word] = coefs
f.close()

print('Found {} word vectors.'.format(len(embeddings_index)))

# Build embedding matrix
embedding_matrix = zeros((len(word_index)+1, embedding_dim))
for word, i in word_index.items():
    if i > vocab_size-1:
        break
    else:
        embedding_vector = embeddings_index.get(word)
        if embedding_vector is not None:
            # Words not found in embedding index will be all-zeros.
            embedding_matrix[i] = embedding_vector

import keras.backend
from keras.models import Sequential
from keras.layers import CuDNNGRU, Dense, Conv1D, MaxPooling1D
from keras.layers import Dropout, GlobalMaxPooling1D, BatchNormalization
from keras.layers import Bidirectional
from keras.layers.embeddings import Embedding
from keras.optimizers import Nadam

# Initate model
model = Sequential()

# Add Embedding layer
model.add(Embedding(len(word_index)+1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True))

# Add Convolutional layer
model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))
model.add(MaxPooling1D(3))
model.add(GlobalMaxPooling1D())
model.add(BatchNormalization())

# Add fully connected layers
model.add(Dense(50, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(6, activation='sigmoid'))

# Summarize the model
model.summary()

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from keras.callbacks import Callback

model.compile(loss='binary_crossentropy', optimizer='Adam',metrics=['accuracy'])

[X, X_val, y, y_val] = train_test_split(processed_X_train, y_train, test_size=0.03, shuffle=False)

graph = model.fit(X, y, epochs=1,batch_size=64,validation_data=(X_val, y_val),verbose=1)

loss, acc_train = model.evaluate(X, y, verbose=0)
loss, acc = model.evaluate(X_val, y_val, verbose=0)
print('Train Accuracy: %f' % (acc_train*100))
print('Test Accuracy: %f' % (acc*100))



predictions = model.predict(processed_X_test, verbose=0)

"""
    Return toxicity probability based on inputed string.
    """
    # Process string
def toxicity_level(string):
  new_string = [string]
  new_string = tokenizer.texts_to_sequences(new_string)
  new_string = pad_sequences(new_string, maxlen=max_len, padding='post', truncating='post')
    
    # Predict
  prediction = model.predict(new_string)
    
  # Print output
  print("Toxicity levels for '{}':".format(string))
  print('Toxic:         {:.0%}'.format(prediction[0][0]))
  print('Severe Toxic:  {:.0%}'.format(prediction[0][1]))
  print('Obscene:       {:.0%}'.format(prediction[0][2]))
  print('Threat:        {:.0%}'.format(prediction[0][3]))
  print('Insult:        {:.0%}'.format(prediction[0][4]))
  print('Identity Hate: {:.0%}'.format(prediction[0][5]))
  print()

  return

toxicity_level('go jump off a bridge jerk')
toxicity_level('i will kill you')
toxicity_level('have a nice day')
toxicity_level('hola, como estas')
toxicity_level('hola mierda joder')

